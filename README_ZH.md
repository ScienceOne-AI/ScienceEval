# ScienceEval

> ä¸€ä¸ªé¢å‘ ScienceOne Base æ¨¡å‹çš„å¼€æºç§‘å­¦æ¨ç†è¯„æµ‹å¥—ä»¶ï¼ŒæŒç»­ç»´æŠ¤ä¸­ï¼Œæ¬¢è¿ç¤¾åŒºå…±åŒå‚ä¸å»ºè®¾ã€‚

<p align="center">
<font size=5>ğŸ“˜</font>
<a target="_self" href="./README.md">
<img style="height:12pt" src="https://img.shields.io/badge/-è‹±æ–‡%20README-blue?style=flat">
</a>
</p>


## ğŸ“š ç›®å½•

- [ScienceEval](#scienceeval)
  - [ğŸ“š ç›®å½•](#-ç›®å½•)
  - [ğŸ“ æ¦‚è¿°](#-æ¦‚è¿°)
  - [ğŸ—‚ï¸ é¡¹ç›®ç»“æ„](#ï¸-é¡¹ç›®ç»“æ„)
  - [ğŸ“Š è¯„æµ‹ç»“æœ](#-è¯„æµ‹ç»“æœ)
  - [ğŸ“– åŸºå‡†æµ‹è¯•é›†ä»‹ç»](#-åŸºå‡†æµ‹è¯•é›†ä»‹ç»)
  - [ğŸš€ å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
    - [1. ç¯å¢ƒå‡†å¤‡](#1-ç¯å¢ƒå‡†å¤‡)
    - [2. èµ‹äºˆ run\_benchmarks.sh æ‰§è¡Œæƒé™](#2-èµ‹äºˆ-run_benchmarkssh-æ‰§è¡Œæƒé™)
    - [3. è¿è¡Œè¯„æµ‹](#3-è¿è¡Œè¯„æµ‹)
      - [åŸºç¡€è¿è¡Œæ–¹å¼](#åŸºç¡€è¿è¡Œæ–¹å¼)
      - [è¿è¡Œå‚æ•°è¯´æ˜](#è¿è¡Œå‚æ•°è¯´æ˜)
        - [å¿…å¡«å‚æ•°](#å¿…å¡«å‚æ•°)
        - [å¯é€‰å‚æ•°](#å¯é€‰å‚æ•°)
  - [ğŸ” å¤ç°è¯„æµ‹ç»“æœ](#-å¤ç°è¯„æµ‹ç»“æœ)
  - [ğŸ“¬ å‚ä¸è´¡çŒ®](#-å‚ä¸è´¡çŒ®)

## ğŸ“ æ¦‚è¿°

ScienceEval æ˜¯ä¸€æ¬¾ä¸“ä¸ºè¯„æµ‹ **ç§‘å­¦æ¨ç†èƒ½åŠ›** è€Œè®¾è®¡çš„å·¥å…·å¥—ä»¶ï¼Œæ”¯æŒåŒ–å­¦ã€ç‰©ç†ã€ç”Ÿç‰©ã€ææ–™ç§‘å­¦ç­‰å¤šä¸ªå­¦ç§‘é¢†åŸŸï¼Œé…ç½®ç®€å•å³å¯è¿è¡Œé«˜æ•ˆè¯„æµ‹ã€‚

**âœ¨ æ ¸å¿ƒç‰¹ç‚¹**

* ğŸ§ª **ç²¾é€‰è¯„æµ‹é›†**ï¼šæ¶µç›– 11 ä¸ªé«˜è´¨é‡åŸºå‡†é›†ï¼ŒåŒ…æ‹¬ SciBenchã€ChemBenchã€TOMG-Benchã€MAQAã€ProteinLMBenchã€Physics ç­‰ã€‚
* ğŸš€ **ä¸€é”®è¿è¡Œ**ï¼šç»Ÿä¸€è„šæœ¬ä¸é¢„è®¾æµæ°´çº¿ï¼Œæ”¯æŒå•å‘½ä»¤å®Œæˆå…¨å¥—è¯„æµ‹ï¼Œæ— éœ€ç¹çé…ç½®ã€‚
* ğŸ§¾ **è¯¦ç»†ç»“æœè¾“å‡º**ï¼šæŒ‰æ ·æœ¬ç”Ÿæˆ JSON è¾“å‡ºï¼ŒåŒ…æ‹¬é¢˜ç›®ã€æ¨¡å‹å›ç­”ã€è¯„åˆ†ã€è°ƒç”¨æ•°æ®ç­‰ï¼Œå¹¶åœ¨ `score.json` ä¸­æä¾›æŒ‰å­¦ç§‘æ‹†åˆ†çš„æ€»è¯„åˆ†åŠè¯Šæ–­ä¿¡æ¯ï¼ˆå¦‚æˆªæ–­ã€æå–å¤±è´¥ç­‰ï¼‰ã€‚

## ğŸ—‚ï¸ é¡¹ç›®ç»“æ„

```
â”œâ”€â”€ benchmarks/         # æ ¸å¿ƒè¯„æµ‹æ¨¡å—
â”‚ â”œâ”€â”€ ChemBench/
â”‚ â”œâ”€â”€ GPQA/
â”‚ â”œâ”€â”€ LAB-Bench/
â”‚ â”œâ”€â”€ LLM-MSE/
â”‚ â”œâ”€â”€ MaScQA/
â”‚ â”œâ”€â”€ MSQA_Long/
â”‚ â”œâ”€â”€ MSQA_Short/
â”‚ â”œâ”€â”€ Physics/
â”‚ â”œâ”€â”€ ProteinLMbench/
â”‚ â”œâ”€â”€ Qiskit_HumanEval/
â”‚ â”œâ”€â”€ SciBench/
â”‚ â””â”€â”€ TOMG-Bench/
â”œâ”€â”€ run_benchmarks.sh   # è¯„æµ‹å¯åŠ¨è„šæœ¬
â”œâ”€â”€ README.md           # é¡¹ç›®è¯´æ˜
â””â”€â”€ requirements.txt    # Python ä¾èµ–
```

* `benchmarks` ç›®å½•åŒ…å«æ‰€æœ‰åŸºå‡†ä»»åŠ¡ï¼Œæ¯ä¸ªå­ç›®å½•å¯¹åº”ä¸€ä¸ªç‹¬ç«‹çš„è¯„æµ‹é›†ã€‚
* `run_benchmarks.sh` ç”¨äºé¡ºåºæ‰§è¡Œå„è¯„æµ‹ä»»åŠ¡ï¼Œå®ç°ä¸€é”®è¿è¡Œã€‚

## ğŸ“Š è¯„æµ‹ç»“æœ

| Model               | Science  |              | Chemistry  |           | Materials Science |       |              | Biology        |           | Physics          |         | MATH     |            |               |       |
| ------------------- | -------- | ------------ | ---------- | --------- | ----------------- | ----- | ------------ | -------------- | --------- | ---------------- | ------- | -------- | ---------- | ------------- | ----- |
|                     | SciBench | GPQA-Diamond | TOMG-Bench | ChemBench | MaScQA            | MSQA  | LLM-MSE-MCQs | ProteinLMBench | LAB-Bench | Qiskit HumanEval | Physics | AIME2024 | AIME2025-I | LiveMathBench | AMC23 |
| Gemini-2.5-Pro      | 50.99    | 86.05        | 78         | 68.02     | 95.34             | 71.23 | 92.7         | 64.64          | 58.72     | 52.98            | 63.38   | 90.8*    | 88*        | 56.25         | 86.75 |
| Claude-Sonnet-4     | 83.53    | 75.06        | 75.44      | 66.4      | 93.17             | 70.18 | 90.82        | 64.37          | 51.11     | 51               | 58      | 43.3     | 70.5*      | 75            | 72.29 |
| OpenAI-o3-High      | 74.63    | 82.26        | 83.44      | 62.06     | 95.34             | 82.5  | 93.58        | 16.51          | 61.96     | 47.02            | 71.14   | 91.6*    | 88.9*      | 89.13         | 81.25 |
| Doubao 1.6 Thinking | 83.99    | 77.97        | 32.56      | 65.79     | 96.27             | 79.23 | 91.92        | 62.63          | 44.92     | 41.72            | 62.3    | 87.67    | 78         | 93.67         | 95.48 |
| DeepSeek-R1-0528    | 84.21    | 80.43        | 70.78      | 62.89     | 96.27             | 77.64 | 89.38        | 62.97          | 45.3      | 45.7             | 61.2    | 91.4*    | 87.5*      | 93.1          | 95.6  |
| Qwen3-235B          | 85.57    | 70.39        | 61.78      | 64.07     | 95.34             | 75.25 | 91.04        | 59.14          | 46.05     | 46.36            | 60.68   | 84.7     | 73.3       | 92.8          | 95.3  |
| Qwen3-32B           | 84.39    | 66.04        | 53.78      | 61.81     | 93.17             | 73.25 | 88.5         | 59.61          | 34.45     | 43.05            | 46.54   | 80.63    | 67.5       | 85.15         | 91.87 |
| Qwen3-8B            | 79.39    | 60.86        | 31.11      | 57.79     | 86.64             | 73.45 | 83.51        | 59.4           | 26.52     | 23.18            | 42.8    | 74.6     | 57.9       | 77            | 88.3  |
| S1-8B-Base          | 82.18    | 63.01        | 59.56      | 62.74     | 90.53             | 73.36 | 88.5         | 69.21          | 37.63     | 45.7             | 50.17   | 75.42    | 52.5       | 82.81         | 88.25 |
| S1-32B-Base         | 86.36    | 69.44        | 63.56      | 63.6      | 94.72             | 74.73 | 91.26        | 68.22          | 41.52     | 48.34            | 56.59   | 81.25    | 69.58      | 84.76         | 92.47 |
| S1-671B-Base        | 85.43    | 83.08        | 74.33      | 68.38     | 95.81             | 82.1  | 91.26        | 69.53          | 52.31     | 54.97            | 55.2    | 88.13    | 83.33      | 93.36         | 96.38 |

> å¸¦ `*` çš„åˆ†æ•°æ¥æºäºæ¨¡å‹å®˜æ–¹å…¬å¼€ç»“æœã€‚

## ğŸ“– åŸºå‡†æµ‹è¯•é›†ä»‹ç»

* [**GPQA**](https://arxiv.org/abs/2311.12022)ï¼šè¯¥è¯„æµ‹é›†ç”¨äºè¯„ä¼°ç ”ç©¶ç”Ÿæ°´å¹³çš„é«˜é˜¶ç§‘å­¦æ¨ç†ä¸çŸ¥è¯†èƒ½åŠ›ã€‚é¢˜ç›®ç”±ç”Ÿç‰©ã€ç‰©ç†ã€åŒ–å­¦é¢†åŸŸçš„ä¸“å®¶ç¼–å†™ï¼Œæ— æ³•é€šè¿‡ç®€å•çš„ Google æœç´¢ç›´æ¥è§£ç­”ã€‚**GPQA-Diamond** æ˜¯ä»å®Œæ•´ GPQA ä¸­ç²¾å¿ƒæŒ‘é€‰çš„é«˜è´¨é‡å­é›†ï¼Œæ—¨åœ¨å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œé«˜è´¨é‡ã€ç¨³å¥çš„è¯„æµ‹ã€‚

* [**SciBench**](https://arxiv.org/abs/2307.10635)ï¼šä¸€ä¸ªæ–°å‹çš„å¤§å­¦æ°´å¹³ç§‘å­¦é—®é¢˜è¯„æµ‹é›†ï¼Œé¢˜ç›®æ¥æºäºæ•™æä¸æ•™å­¦ææ–™ã€‚æ—¨åœ¨æµ‹è¯• LLM çš„å¤æ‚æ¨ç†èƒ½åŠ›ã€æ·±åšçš„å­¦ç§‘çŸ¥è¯†ä»¥åŠé«˜é˜¶è®¡ç®—èƒ½åŠ›ï¼Œè¦†ç›–æ•°å­¦ã€åŒ–å­¦ã€ç‰©ç†ç­‰é¢†åŸŸã€‚

* [**TOMG-Bench**](https://arxiv.org/abs/2412.14642)ï¼šé¦–ä¸ªé¢å‘å¼€æ”¾åŸŸåˆ†å­ç”Ÿæˆèƒ½åŠ›çš„è¯„æµ‹é›†ã€‚åŒ…å«ä¸‰å¤§æ ¸å¿ƒä»»åŠ¡ï¼šåˆ†å­ç¼–è¾‘ï¼ˆMolEditï¼‰ã€åˆ†å­ä¼˜åŒ–ï¼ˆMolOptï¼‰å’Œå®šåˆ¶åˆ†å­ç”Ÿæˆï¼ˆMolCustomï¼‰ï¼Œæ¯ä¸ªä»»åŠ¡ä¸‹è®¾å¤šä¸ªå­ä»»åŠ¡ã€‚ä¸ºåº”å¯¹å¼€æ”¾åŸŸåˆ†å­ç”Ÿæˆçš„å¤æ‚æ€§ï¼Œè¯¥åŸºå‡†é›†å¼•å…¥è‡ªåŠ¨åŒ–è¯„æµ‹ç³»ç»Ÿï¼Œæ—¢è¡¡é‡åŒ–å­¦å‡†ç¡®æ€§ï¼Œä¹Ÿè¯„ä¼°ç”Ÿæˆåˆ†å­çš„åŠŸèƒ½æ€§è´¨ã€‚TOMG-Bench æ˜¯å‘ç°æ–‡æœ¬é©±åŠ¨åˆ†å­å‘ç°ä¸­å±€é™ä¸æ”¹è¿›æ–¹å‘çš„é‡è¦å·¥å…·ã€‚

* [**ChemBench**](https://arxiv.org/abs/2404.01475)ï¼šç”¨äºè¯„ä¼° LLM åœ¨åŒ–å­¦é¢†åŸŸçš„çŸ¥è¯†ä¸æ¨ç†èƒ½åŠ›ã€‚æ•°æ®é›†åŒ…å« 2,788 é“é—®ç­”é¢˜ï¼Œè¦†ç›–ä»æœ¬ç§‘åˆ°ç ”ç©¶ç”Ÿé˜¶æ®µçš„åŒ–å­¦è¯¾ç¨‹ï¼ˆåŒ…æ‹¬æœ‰æœºåŒ–å­¦ã€ç‰©ç†åŒ–å­¦ã€åˆ†æåŒ–å­¦ç­‰ï¼‰ã€‚æŒ‰ç…§æŠ€èƒ½ï¼ˆçŸ¥è¯†ã€æ¨ç†ã€è®¡ç®—ã€ç›´è§‰ï¼‰åŠéš¾åº¦åˆ†çº§ï¼Œé¢˜å‹åŒ…æ‹¬é€‰æ‹©é¢˜ä¸å¼€æ”¾æ€§é—®ç­”ã€‚éƒ¨åˆ†é¢˜ç›®æ¥æºäºäººå·¥æˆ–åŠè‡ªåŠ¨ç”Ÿæˆï¼ŒåŸºäºå¤§å­¦è€ƒè¯•ã€æ•™æåŠæ•°æ®åº“æ•´ç†ã€‚

* [**PHYSICS**](https://arxiv.org/abs/2503.21821)ï¼šä¸€ä¸ªå…¨é¢çš„å¤§å­¦ç‰©ç†èƒ½åŠ›è¯„æµ‹é›†ï¼Œæ”¶å½• 1,297 é“ä¸“å®¶ç²¾å¿ƒç¼–å†™çš„é¢˜ç›®ï¼Œæ¶µç›–å…­å¤§åŸºç¡€é¢†åŸŸï¼šç»å…¸åŠ›å­¦ã€é‡å­åŠ›å­¦ã€çƒ­åŠ›å­¦ä¸ç»Ÿè®¡åŠ›å­¦ã€ç”µç£å­¦ã€åŸå­ç‰©ç†ä¸å…‰å­¦ã€‚æ¯é“é¢˜éƒ½éœ€è¦æ‰å®çš„ç‰©ç†çŸ¥è¯†ä¸é«˜é˜¶æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚

* [**Qiskit HumanEval**](https://arxiv.org/abs/2406.14712)ï¼šç”± 151 é“äººå·¥ç¼–å†™çš„é‡å­è®¡ç®—ä»»åŠ¡æ„æˆï¼Œç”¨äºè¯„ä¼° LLM åœ¨ Qiskit ä»£ç ç”Ÿæˆæ–¹é¢çš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†é›†æ—¢æ˜¯é‡å­è½¯ä»¶å¼€å‘ AI èƒ½åŠ›çš„æ ‡å‡†åŒ–è¯„æµ‹å·¥å…·ï¼Œä¹Ÿå±•ç¤ºäº† LLM åœ¨é‡å­ç¼–ç¨‹é¢†åŸŸçš„æ½œåŠ›ã€‚

* [**MaScQA**](https://arxiv.org/abs/2308.09115)ï¼šææ–™ç§‘å­¦é¢†åŸŸçš„ç»¼åˆè¯„æµ‹é›†ï¼ŒåŒ…å« 650 é“é¢˜ï¼Œåæ˜ æœ¬ç§‘ææ–™ä¸“ä¸šå­¦ç”Ÿåº”å…·å¤‡çš„çŸ¥è¯†ä¸èƒ½åŠ›ã€‚é¢˜ç›®æ¥è‡ªå°åº¦å·¥ç¨‹ç ”ç©¶ç”Ÿå…¥å­¦è€ƒè¯•ï¼ˆGATEï¼‰çš„ææ–™ç§‘å­¦ä¸å†¶é‡‘å·¥ç¨‹ç§‘ç›®ï¼Œæ¶µç›– 13 ä¸ªæ ¸å¿ƒæ–¹å‘ï¼šåŸå­ç»“æ„ã€åŠ›å­¦ã€ææ–™åˆ¶é€ ã€ææ–™åº”ç”¨ã€ç›¸å˜ã€ç”µå­¦æ€§è´¨ã€ææ–™åŠ å·¥ã€ä¼ è¾“ç°è±¡ã€ç£å­¦ã€ææ–™è¡¨å¾ã€æµä½“åŠ›å­¦ã€ææ–™æ£€æµ‹ä¸çƒ­åŠ›å­¦ã€‚

* [**LLM-MSE**](https://arxiv.org/abs/2409.14572)ï¼šææ–™ç§‘å­¦é¢†åŸŸçš„ç»¼åˆæ€§è¯„æµ‹é›†ï¼ŒåŒ…å«ä¸‰ä¸ªå­æ•°æ®é›†ã€‚æœ¬é¡¹ç›®ä½¿ç”¨å…¶ä¸­çš„å¤šé€‰é¢˜é›†ï¼ˆLLM-MCQsï¼‰ï¼Œé¢˜ç›®ç”±ææ–™é¢†åŸŸä¸“å®¶ä¸ºæœ¬ç§‘ä¸€å¹´çº§è¯¾ç¨‹ç¼–å†™ï¼Œè¦†ç›–ææ–™åŠ›å­¦ã€çƒ­åŠ›å­¦ã€æ™¶ä½“ç»“æ„ä¸ææ–™æ€§èƒ½ç­‰æ–¹å‘ã€‚

* [**MSQA**](https://arxiv.org/abs/2505.23982)ï¼šææ–™ç§‘å­¦é¢†åŸŸçš„ç»¼åˆè¯„æµ‹é›†ï¼Œæ—¨åœ¨è¯„ä¼° LLM åœ¨è¯¥é¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ä¸å¤æ‚æ¨ç†èƒ½åŠ›ã€‚åŒ…å« 1,757 é“ç ”ç©¶ç”Ÿæ°´å¹³çš„é¢˜ç›®ï¼Œåˆ†ä¸ºä¸¤ç§å½¢å¼ï¼šè¯¦ç»†è§£é‡Šå‹å›ç­”å’ŒäºŒå…ƒåˆ¤æ–­ï¼ˆçœŸ/å‡ï¼‰ã€‚é¢˜ç›®è¦†ç›–ææ–™ç§‘å­¦çš„ä¸ƒå¤§å…³é”®å­é¢†åŸŸï¼Œå¦‚ç»“æ„ä¸æ€§èƒ½å…³ç³»ã€åˆæˆå·¥è‰ºã€è®¡ç®—å»ºæ¨¡ç­‰ã€‚æ¯é“é¢˜éƒ½è¦æ±‚ç²¾å‡†çš„äº‹å®çŸ¥è¯†ä¸å¤šæ­¥éª¤æ¨ç†ã€‚è¯¦ç»†è§£é‡Šå‹å¯¹åº” **MSQA_Long**ï¼Œåˆ¤æ–­é¢˜å¯¹åº” **MSQA_Short**ã€‚

* [**ProteinLMBench**](https://arxiv.org/abs/2406.05540)ï¼šç”¨äºè¯„ä¼° LLM å¯¹è›‹ç™½è´¨åºåˆ—çš„ç†è§£èƒ½åŠ›ã€‚æ•°æ®é›†åŒ…å« 944 é“ç»äººå·¥æ ¸éªŒçš„å¤šè¯­è¨€é€‰æ‹©é¢˜ï¼Œæ¶µç›–è›‹ç™½è´¨æ€§è´¨é¢„æµ‹ã€æ–‡æœ¬æè¿°è§£æã€åºåˆ—åˆ†æç­‰æ ¸å¿ƒä»»åŠ¡ã€‚

* [**LAB-Bench**](https://arxiv.org/abs/2407.10362)ï¼šä¸€ä¸ªæ¶µç›– 2,400 å¤šé“é€‰æ‹©é¢˜çš„ç»¼åˆè¯„æµ‹é›†ï¼Œç”¨äºæµ‹è¯• AI ç³»ç»Ÿåœ¨å®é™…ç”Ÿç‰©ç ”ç©¶ä»»åŠ¡ä¸­çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬æ–‡çŒ®ç†è§£ä¸æ¨ç†ï¼ˆLitQA2ã€SuppQAï¼‰ã€å›¾è¡¨è§£æï¼ˆFigQAã€TableQAï¼‰ã€æ•°æ®åº“è®¿é—®ï¼ˆDbQAï¼‰ã€å®éªŒæ–¹æ¡ˆæ’°å†™ï¼ˆProtocolQAï¼‰ä»¥åŠåºåˆ—æ“ä½œï¼ˆSeqQAã€CloningScenariosï¼‰ã€‚ç”±äº LitQA2 ä¸ SuppQA ä¾èµ–å·¥å…·ï¼ŒFigQA ä¸ TableQA éœ€è¦è§†è§‰èƒ½åŠ›ï¼Œæœ¬é¡¹ç›®é€‰æ‹© **ProtocolQAã€SeqQAã€CloningScenariosã€DbQA** å››ä¸ªå­ä»»åŠ¡è¿›è¡Œè¯„æµ‹ã€‚


## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# ï¼ˆå¯é€‰ï¼‰åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n science_eval python=3.12
conda activate science_eval

# å®‰è£…æ ¸å¿ƒä¾èµ–
cd scienceeval
pip install -r requirements.txt

# å®‰è£… ChemBench ä¾èµ–ï¼ˆæµ‹è¯• ChemBench å¿…éœ€ï¼‰
cd benchmarks/ChemBench
pip install -e .

# å®‰è£… LAB-Bench ä¾èµ–ï¼ˆæµ‹è¯• LAB-Bench å¿…éœ€ï¼‰
cd benchmarks/LAB-Bench
pip install -e .
```

### 2. èµ‹äºˆ run_benchmarks.sh æ‰§è¡Œæƒé™

```bash
chmod +x run_benchmarks.sh
```

### 3. è¿è¡Œè¯„æµ‹

#### åŸºç¡€è¿è¡Œæ–¹å¼

```bash
./run_benchmarks.sh \
  --api_url your-api-url \
  --api_key your-api-key \
  --model your-model \
  --num_workers 10 \
  --benchmarks scibench gpqa chembench  # ä¸æŒ‡å®šåˆ™è¿è¡Œå…¨éƒ¨
```

è¿è¡Œæµç¨‹ï¼š

* æ‰§è¡Œå¯¹åº”è¯„æµ‹é›†çš„ `run.py` è„šæœ¬
* æ—¥å¿—ä¿å­˜åœ¨å„è¯„æµ‹ç›®å½•ä¸‹çš„ `logs` æ–‡ä»¶å¤¹
* è®¡ç®—å¾—åˆ†å¹¶ç”Ÿæˆ `evaluation.json` ä¸ `score.json`

> âš ï¸ ä»…æ”¯æŒ OpenAI API å…¼å®¹çš„æ¥å£ï¼ˆè¯„æµ‹æ¨¡å‹ä¸åˆ¤åˆ†æ¨¡å‹å‡éœ€å¦‚æ­¤ï¼‰
> ğŸŒ è¿è¡Œ ChemBench é¦–æ¬¡éœ€è¦è”ç½‘ä¸‹è½½æ•°æ®é›†ï¼ˆHugging Face Datasets Hubï¼‰

#### è¿è¡Œå‚æ•°è¯´æ˜

##### å¿…å¡«å‚æ•°

* `--api_url`ï¼šOpenAI å…¼å®¹æ¥å£åœ°å€ï¼Œå¦‚ `http://127.0.0.1:8000/v1`
* `--model`ï¼šAPI æ¥å£çš„æ¨¡å‹åç§°

<details>
  <summary>ç‚¹å‡»å±•å¼€/å¯é€‰å‚æ•°</summary>

##### å¯é€‰å‚æ•°

* `--api_key` *(strï¼Œé»˜è®¤ï¼šç¯å¢ƒå˜é‡ `API_KEY`ï¼Œå¦åˆ™ä¸º `"EMPTY"`)*
  ä¸»è¯„æµ‹æ¨¡å‹çš„ API Keyã€‚è‹¥æœªæŒ‡å®šï¼Œåˆ™ä»ç¯å¢ƒå˜é‡ `API_KEY` è¯»å–ï¼›è‹¥ç¯å¢ƒå˜é‡ä¹Ÿæœªè®¾ç½®ï¼Œåˆ™é»˜è®¤ä¸º `"EMPTY"`ã€‚

* `--num_workers` *(intï¼Œé»˜è®¤ï¼š64)*
  å¹¶å‘æ‰§è¡Œç”Ÿæˆ/è¯„æµ‹çš„çº¿ç¨‹æ•°ã€‚

* `--max_tokens` *(intï¼Œé»˜è®¤ï¼šNone)*
  æ¯æ¬¡ç”Ÿæˆçš„æœ€å¤§ token æ•°ã€‚å¦‚æœä¸º `None`ï¼Œåˆ™è¯·æ±‚ä¸­ä¸ä¼šåŒ…å«è¯¥å‚æ•°ã€‚

* `--temperature`, `--top_p`, `--presence_penalty` *(floatï¼Œé»˜è®¤ï¼šNone)*
  æŠ½æ ·ç›¸å…³å‚æ•°ã€‚è‹¥æœªæŒ‡å®šï¼Œåˆ™ä¸ä¼šåŒ…å«åœ¨ API è¯·æ±‚ä¸­ã€‚

* `--timeout` *(intï¼Œé»˜è®¤ï¼š3600)*
  å•æ¬¡è¯·æ±‚çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ã€‚

* `--judge_api_url` *(strï¼Œé»˜è®¤ï¼šNone)*
  ç”¨äºè¯„åˆ†çš„åˆ¤åˆ†æ¨¡å‹ API åœ°å€ï¼ˆå¯é€‰ï¼‰ã€‚

* `--judge_api_key` *(strï¼Œé»˜è®¤ï¼šç¯å¢ƒå˜é‡ `JUDGE_API_KEY`ï¼Œå¦åˆ™ä¸º `"EMPTY"`)*
  åˆ¤åˆ†æ¨¡å‹çš„ API Keyã€‚è‹¥æœªæŒ‡å®šï¼Œåˆ™ä»ç¯å¢ƒå˜é‡ `JUDGE_API_KEY` è¯»å–ï¼›è‹¥ç¯å¢ƒå˜é‡ä¹Ÿæœªè®¾ç½®ï¼Œåˆ™é»˜è®¤ä¸º `"EMPTY"`ï¼ˆå³ä¸è¿›è¡Œèº«ä»½éªŒè¯ï¼‰ã€‚

* `--judge_model` *(strï¼Œé»˜è®¤ï¼šNone)*
  ä¼ é€’ç»™åˆ¤åˆ† API çš„æ¨¡å‹åç§°ã€‚

* `--benchmarks` *(listï¼Œé»˜è®¤ï¼šNone)*
  è¦æ‰§è¡Œçš„åŸºå‡†é›†åç§°åˆ—è¡¨ï¼ˆä»¥ç©ºæ ¼åˆ†éš”ï¼Œå°å†™+ä¸‹åˆ’çº¿ï¼‰ã€‚å°†æŒ‰é¡ºåºè¿è¡ŒæŒ‡å®šçš„è¯„æµ‹ä»»åŠ¡ï¼›è‹¥ä¸æŒ‡å®šï¼Œåˆ™é»˜è®¤è¿è¡Œå…¨éƒ¨å¯ç”¨ä»»åŠ¡ã€‚

**æ”¯æŒçš„åŸºå‡†é›†**

ä¸‹è¡¨åˆ—å‡ºäº†å½“å‰æ”¯æŒçš„è¯„æµ‹é›†ï¼Œç‚¹å‡»åç§°å¯æŸ¥çœ‹å¯¹åº” READMEã€‚

| æ•°æ®é›†åç§°             | å®˜æ–¹åç§°                                                        | å­¦ç§‘é¢†åŸŸ     |
| ----------------- | ----------------------------------------------------------- | -------- |
| scibench          | [SciBench](./benchmarks/SciBench/README.md)                 | ç‰©ç†ã€æ•°å­¦ã€åŒ–å­¦ |
| gpqa              | [GPQA](./benchmarks/GPQA/README.md)                         | ç‰©ç†ã€åŒ–å­¦ã€ç”Ÿç‰© |
| chembench         | [ChemBench](./benchmarks/ChemBench/README.md)               | åŒ–å­¦       |
| tomg_bench       | [TOMG-Bench](./benchmarks/TOMG-Bench/README.md)             | åŒ–å­¦       |
| llm_mse          | [LLM-MSE](./benchmarks/LLM-MSE/README.md)                   | ææ–™ç§‘å­¦     |
| mascqa            | [MaScQA](./benchmarks/MaScQA/README.md)                     | ææ–™ç§‘å­¦     |
| msqa_long        | [MSQA-Long](./benchmarks/MSQA_Long/README.md)               | ææ–™ç§‘å­¦     |
| msqa_short       | [MSQA-Short](./benchmarks/MSQA_Short/README.md)             | ææ–™ç§‘å­¦     |
| physics           | [Physics](./benchmarks/Physics/README.md)                   | ç‰©ç†       |
| qiskit_humaneval | [Qiskit-HumanEval](./benchmarks/Qiskit_HumanEval/README.md) | ç‰©ç†       |
| protein_lmbench  | [ProteinLMbench](./benchmarks/ProteinLMbench/README.md)     | ç”Ÿç‰©       |
| lab_bench        | [LAB-Bench](./benchmarks/LAB-Bench/README.md)               | ç”Ÿç‰©       |

</details>

## ğŸ” å¤ç°è¯„æµ‹ç»“æœ

è¦å¤ç° ScienceOne åŸºåº§æ¨¡å‹çš„è¯„æµ‹ç»“æœï¼š

* S1-8B-Base å’Œ S1-32B-Base çš„æœ€å¤§ç”Ÿæˆé•¿åº¦è®¾ä¸º **38,000 tokens**
* S1-671B-Base è®¾ä¸º **48,000 tokens**
* è§£ç å‚æ•°ï¼š`temperature=0.6`ï¼Œ`top_p=0.95`
* å¯¹éœ€è¦é‡‡æ ·çš„åŸºå‡†ï¼ˆå¦‚ GPQA-Diamondã€LLM-MSEï¼‰ï¼Œæ¯é“é¢˜ç”Ÿæˆ **8 ä¸ªç­”æ¡ˆ** ç”¨äºä¼°ç®— pass\@1
* `presence_penalty` åœ¨ TOMG-Benchã€Qiskit-HumanEvalã€GPQA-Diamondã€Physics ä¸­è®¾ä¸º `1.0`ï¼Œå…¶ä½™ä»»åŠ¡è®¾ä¸º `0.0`

ç¤ºä¾‹å‘½ä»¤å¦‚ä¸‹ï¼š

```shell
# SciBench
cd benchmarks/SciBench
python -u run.py --model your-model --api_url your-api-url --api_key your-api-key --temperature 0.6 --top_p 0.95 --presence_penalty 0.0 --timeout 3600 --num_workers 10

# GPQA
cd benchmarks/GPQA
python -u run.py --model your-model --api_url your-api-url --api_key your-api-key --temperature 0.6 --top_p 0.95 --presence_penalty 1.0 --timeout 3600 --n 8 --num_workers 10

# TOMG-Bench
cd benchmarks/TOMG-Bench
python -u run.py --model your-model --api_url your-api-url --api_key your-api-key --temperature 0.6 --top_p 0.95 --presence_penalty 1.0 --timeout  3600 --num_workers 10

# ChemBench
cd benchmarks/ChemBench
python -u run.py --model your-model --api_url your-api-url --api_key your-api-key --temperature 0.6 --top_p 0.95 --presence_penalty 0.0 --timeout 3600 --num_workers 10 

# LLM-MSE
cd benchmarks/LLM-MSE
python -u run.py --model your-model --api_url your-api-url --api_key your-api-key --temperature 0.6 --top_p 0.95 --presence_penalty 0.0 --timeout 3600 --n 8 --judge_api_url your-judge-api-url --judge_model your-judge-model --judge_api_key your-judge-api-key --num_workers 10 

# MaScQA
cd benchmarks/MaScQA
python -u run.py --model your-model --api_url your-api-url --api_key your-api-key --temperature 0.6 --top_p 0.95 --presence_penalty 0.0 --timeout 3600 --judge_api_url your-judge-api-url --judge_model your-judge-model --judge_api_key your-judge-api-key --num_workers 10 

# MSQA_Long
cd benchmarks/MSQA_Long
python -u run.py --model your-model --api_url your-api-url --api_key your-api-key --temperature 0.6 --top_p 0.95 --presence_penalty 0.0 --timeout 3600 --judge_api_url your-judge-api-url --judge_model your-judge-model --judge_api_key your-judge-api-key --num_workers 10

# MSQA_Short
cd benchmarks/MSQA_Short
python -u run.py --model your-model --api_url your-api-url --api_key your-api-key --temperature 0.6 --top_p 0.95 --presence_penalty 0.0 --timeout 3600 --num_workers 10

# Physics
cd benchmarks/Physics
python -u run.py --model your-model --api_url your-api-url --api_key your-api-key --temperature 0.6 --top_p 0.95 --presence_penalty 1.0 --timeout 3600 --judge_api_url your-judge-api-url --judge_model your-judge-model --judge_api_key your-judge-api-key --num_workers 10

# Qiskit_HumanEval
cd benchmarks/Qiskit_HumanEval
python -u run.py --model your-model --api_url your-api-url --api_key your-api-key --temperature 0.6 --top_p 0.95 --presence_penalty 1.0 --timeout 3600 --num_workers 10 

# ProteinLMbench
cd benchmarks/ProteinLMBench
python -u run.py --model your-model --api_url your-api-url --api_key your-api-key --temperature 0.6 --top_p 0.95 --presence_penalty 0.0 --timeout 3600 --num_workers 10

# LAB-Bench
cd benchmarks/LAB-Bench
python -u run.py --model your-model --api_url your-api-url --api_key your-api-key --temperature 0.6 --top_p 0.95 --presence_penalty 0.0 --timeout 3600 --num_workers 10
```

## ğŸ“¬ å‚ä¸è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ä¸åé¦ˆå»ºè®®ï¼ä½ å¯ä»¥é€šè¿‡æäº¤ **Issue** æˆ– **Pull Request** æ¥å‚ä¸é¡¹ç›®ã€‚